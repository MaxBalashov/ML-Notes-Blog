{
  
    
        "post0": {
            "title": "Нейронные сети",
            "content": "TL; DL . Выбор функции ошибки: Кратко; | Интуитивный подход; | | Устройство нейронных сетей; | Поиск минимума функции ошибки (TODO: ссылка на градиентный спуск); | Градиентный спуск в нейросетях (Backpropagation): градиентный спуск; | вычислительные графы. | | &#1055;&#1086;&#1089;&#1090;&#1072;&#1085;&#1086;&#1074;&#1082;&#1072; &#1079;&#1072;&#1076;&#1072;&#1095;&#1080; . Главной отличительной особенностью &quot;Обучение с учиталем&quot;(Superwised learning) является наличие обучающей выборки, состоящий из пар $x_i, y_i$, где $x_i$ - признаковое представление объекта, $y_i$ - целевая переменная. В этой области машинного обучения встают задачи классификации, регрессии и тд. . Рассмотрим задачу регресии. TODO: рассписать . &#1042;&#1099;&#1073;&#1086;&#1088; &#1092;&#1091;&#1085;&#1082;&#1094;&#1080;&#1080; &#1086;&#1096;&#1080;&#1073;&#1082;&#1080; . &#1048;&#1085;&#1090;&#1091;&#1080;&#1090;&#1080;&#1074;&#1085;&#1099;&#1081; &#1087;&#1086;&#1076;&#1093;&#1086;&#1076; . Задача регрессии, если упростить, сводится к тому, чтобы модель, описывающая &quot;скрытую в данных&quot; функциональную зависимость, не ошибалась. (Не учитываем погрешность при измерениях и переобучение) Модель не ошибается, когда спрогнозированные значения совпадают с реальными (или стремятся к ним). . Как можно проверить, насколько модель ошибается? Нужно придумать подходящую функцию ошибки. Например, мы можем измерять разницу между реальным ($y_i$) и прогнозным ($ hat{y_i}$) значением для объекта из обучающей (или валидационной) выборки: . $$y_i - hat{y_i}$$ . Но измерение ошибки модели в одной контрольной точке $i$ малоинформативно, возьмем сумму ошибок по всей обучаюшей выборке ($N$ - число наблюдений в выборке): $$ sum_i^N{y_i - hat{y_i}}$$ . Вот тут мы и встречаем причину, почему просто разность в качестве функции ошибки не подходит: . Ошибки модели на разных примерах из обучающей выборки могут иметь разные знаки, компенсируя друг друга при сложении. . Пример, пусть существуют две модели A и B, которые имеют следующие ошибки $e_i = y_i - hat{y_i}$: . модель $e_1$ $e_2$ $e_3$ $e_4$ $ sum_i^N{e_i}$ . A | +3 000 | -1 000 | -1 000 | -1 000 | 0 | . B | +1 | +2 | +1 | +3 | 7 | . Получается, что: . Для модели A суммарная ошибка будет равна 0, в то время как суммарная ошибка модели B будет равна 7. . Исходя из этой логики модель A лучше, чем B. . Hо это противоречит здравому смыслу, т.к. в каждой точке модель B лучше, т.е. меньше ошибается, чем модель A. ¯ _(ツ)_/¯ . Ключевая проблема в том, что ошибки с разными знаками компенсируют друг друга. Чтобы исправить этот недостаток, можно сделать такое преобразование над ошибками, которое уберет влияние знака. . Ниже представленны примеры таких преобразований и формулы суммарной ошибки модели в результате этих преобразований:- $|x|$ (модуль числа):$$ sum_i^N{ lvert e_i rvert} = sum_i^N{ lvert y_i - hat{y_i} rvert}$$ . $x^2$ (квадрат числа): $$ sum_i^N{e_i^2} = sum_i^N{(y_i - hat{y_i})^2}$$ | . Рассмотрим уже известный пример с добавлением новых функций ошибки: . модель $e_1$ $e_2$ $e_3$ $e_4$ $ sum_i^N{e_i}$ $ sum_i^N{ lvert e_i rvert}$ $ sum_i^N{e_i^2}$ . A | +3 000 | -1 000 | -1 000 | -1 000 | 0 | 6 000 | 12 000 000 | . B | +1 | +2 | +1 | +3 | 7 | 7 | 15 | . Как можно видеть из таблицы, новые функции ошибки отражают следующий факт, что: . Модель A, которая на каждом наблюдении ошибалась сильнее, также сильнее ошибается в общем по всей выборке. . Поэтому модель A хуже, чем модель B. . Полезное свойство модуля и возведения в квадрат числа - функции ошибки теперь ограничены снизу нулем, те нуль мы получаем в случае, если модель не ошибается и всегда верно предсказывает значение целевой функции. . Напоследок, предлагаю перейти от суммарных ошибок, к усредненным по наблюдениям, т.е.:- Средняя абсолютная ошибка или MAE (Mean absolute error):$$ frac{1}{N} sum_i^N{ lvert y_i - hat{y_i} rvert}$$ . Среднеквадратичная ошибка или MSE (Mean squared error): $$ frac{1}{N} sum_i^N{(y_i - hat{y_i})^2}$$ | . Пример для наглядности: . модель $e_1$ $e_2$ $e_3$ $e_4$ $ frac{1}{N} sum_i^N{e_i}$ MAE MSE . A | +3 000 | -1 000 | -1 000 | -1 000 | 0 | 1 500 | 4 000 000 | . B | +1 | +2 | +1 | +3 | 1.75 | 1.75 | 1.75 | . Теперь функция ошибки отображает, как в среднем ошибается модель. . Также размер значения усредненной функции ошибки не зависит напрямую от количества объектов в выборке. Это удобно для сравнения полученных ошибок на обучающей, валидационной и тестовой выборках. Ведь усреднение нивелирует рост значения функции ошибки из-за увеличения числа объектов, по которым ошибка расчитывается. . &#1053;&#1077;&#1081;&#1088;&#1086;&#1089;&#1077;&#1090;&#1080; . TODO . &#1055;&#1086;&#1080;&#1089;&#1082; &#1084;&#1080;&#1085;&#1080;&#1084;&#1091;&#1084;&#1072; &#1092;&#1091;&#1085;&#1082;&#1094;&#1080;&#1080; &#1086;&#1096;&#1080;&#1073;&#1082;&#1080; . Для начала, выберем функцию ошибки для нашей модели - пусть это будет MSE: $$L( theta) = frac{1}{N} sum_i^N{(y_i - hat{y_i})^2}$$ . TODO: почему MSE??? - оптимизация через град спуск . Повторимся, в упрощенном и интуитивном понимании, для решения задачи регрессии: . Ищем такую модель, которая ошибается как можно меньше, т.е. ее ошибка стремится к минимуму. . Если выразить математически, минимизация функции ошибки выглядит так:$$L( theta) = frac{1}{N} sum_i^N{(y_i - hat{y_i})^2} rightarrow min_{ theta}$$ .",
            "url": "https://maxbalashov.github.io/ml-notes/jupyter/theory/2020/05/24/Neural-networks.html",
            "relUrl": "/jupyter/theory/2020/05/24/Neural-networks.html",
            "date": " • May 24, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Golang Notes",
            "content": ". Объявление переменных . // краткое объявление переменной (наиболее компактное) // может использоваться только внутри функции, // но не для переменных уровня пакета s := &quot;&quot; . // инициализация по умолчанию // для строки — значением &quot;&quot; var s string . // используется редко // в основном при объявлении несколь­ких переменных var s = &quot;&quot; . // содержит явное указание типа перемен­ной // является излишним, когда тип совпадает с типом начального значения переменной, // но является обязательным в других случаях, когда типы пере­менной и инициализатора разные var s string = &quot;&quot; . На практике обычно следует использовать одну из первых двух разновидностей: . с явной инициализацией (чтобы указать важность начального значения); | с неявной инициализацией по умолчанию (чтобы указать, что начальное значение не играет роли). | . Цикл for . Цикл for является единственной инструкцией цикла в Go. Он имеет ряд разно­видностей. . // Традиционный цикл `for` for инициализация; условие; последействие { // нуль или несколько инструкций } . // Традиционный цикл `while` for condition { // ... } . // Традиционный бесконечный цикл for { // ... } . Бесконечный цикл, должен завершиться некоторым иным пу­тем, например с помощью инструкции break или return. . Разновидность цикла for выполняет итерации для диапазона значений для типа данных наподобие строки или среза. . for i, arg := range someSlice { // ... } . Если мы не нуждаемся в индексе, то его можно заменить на пустой идентификатор (blank identifier) с именем _ (символ подчеркивания). Пустой идентификатор может использоваться вез­де, где синтаксис требует имя переменной, но логике программы он не нужен. . for _, arg := range someSlice { // ... } . if с краткой инструкцией . Так же как и for, оператор if может начинаться с инструкции, которая будет выполнена перед проверкой условия. . Переменные объявленные в этом блоке доступны только в области видимости, которая существует до конца if. . Переменные объявленные внутри краткой инструкции if также доступны внутри всех else блоков. . (Попробуйте использовать v в последнем операторе return.) . func pow(x, n, lim float64) float64 { if v := math.Pow(x, n); v &lt; lim { return v } else { fmt.Printf(&quot;%g &gt;= %g n&quot;, v, lim) } // can&#39;t use v here, though return lim } . switch . Вероятно вы уже догадались, на что будет похож switch. . Блок case прерывается автоматически, только если он не заканчивается оператором fallthrough. . package main import &quot;fmt&quot; func main() { // инициализируем внутри переменную `switch` // `swichCondition` существует только в рамках данного `switch` ??? switch swichCondition := 2; swichCondition { case 1: fmt.Println(&quot;Case 1&quot;) case 2: // выполнит принт согласно условию `swichCondition` fmt.Println(&quot;Case 2&quot;) // продолжит проверять последующие условия из-за `fallthrough` fallthrough default: fmt.Printf(&quot;Case default&quot;) } } . switch без условия . switch без условия это тоже самое, что и switch true. . Эта конструкция может быть использована как более ясный способ записи длинной цепочки if-then-else. . package main import ( &quot;fmt&quot; &quot;time&quot; ) func main() { t := time.Now() switch { case t.Hour() &lt; 12: fmt.Println(&quot;Good morning!&quot;) case t.Hour() &lt; 17: fmt.Println(&quot;Good afternoon.&quot;) default: fmt.Println(&quot;Good evening.&quot;) } } . Размер и вместимость среза . Срез имеет размер (длину) и вместимость. . Размер среза - это количество элементов, которые он содержит. . Вместимость среза - это количество элементов в его нижележащем массиве, начиная с первого элемента в срезе. . Размер и вместимость среза s могут быть получены с помощью len(s) и cap(s). . Размер среза может быть увеличен путем повторной операции “срезания”, при условии, что он обладает достаточной вместимостью. . Срезы по верхней границей не меняют вместимость исходного среза. Срезы по нижней границе изменяют исходный срез, уменьшая его вместимость. . import &quot;fmt&quot; func main() { s := []int{2, 3, 5, 7, 11, 13} printSlice(s) // Slice the slice to give it zero length. s = s[:0] printSlice(s) // Extend its length. s = s[:4] printSlice(s) // Вернем срез к исходному состоянию s = s[:6] printSlice(s) // Drop its first two values. // После этой операции вместимость среза `s` уменьшится. // Два первых элемента будут удалены из среза s = s[2:] printSlice(s) // Будет удален еще один элемент // Из-за среза по нижней границе s = s[1:3] printSlice(s) } func printSlice(s []int) { fmt.Printf(&quot;len=%d cap=%d %v n&quot;, len(s), cap(s), s) } . Output: len=6 cap=6 [2 3 5 7 11 13] len=0 cap=6 [] len=4 cap=6 [2 3 5 7] len=6 cap=6 [2 3 5 7 11 13] len=4 cap=4 [5 7 11 13] len=2 cap=3 [7 11] . Указатели на структуры . Доступ к полям структуры может быть получен через указатель на структуру. . Чтобы получить поле X структуры, когда у нас есть указатель на структуру p, мы можем написать: . (*p).X | p.X (без явного разыменования) | . package main import &quot;fmt&quot; type Vertex struct { X int Y int } func main() { v := Vertex{1, 2} p := &amp;v p.X = 1e9 fmt.Println(v) // {1000000000 2} } .",
            "url": "https://maxbalashov.github.io/ml-notes/markdown/programming/2020/05/24/Golang-notes.html",
            "relUrl": "/markdown/programming/2020/05/24/Golang-notes.html",
            "date": " • May 24, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://maxbalashov.github.io/ml-notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://maxbalashov.github.io/ml-notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}