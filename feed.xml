<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://maxbalashov.github.io/ml-notes/feed.xml" rel="self" type="application/atom+xml" /><link href="https://maxbalashov.github.io/ml-notes/" rel="alternate" type="text/html" /><updated>2020-05-24T12:16:21-05:00</updated><id>https://maxbalashov.github.io/ml-notes/feed.xml</id><title type="html">ML Notes</title><entry><title type="html">Нейронные сети</title><link href="https://maxbalashov.github.io/ml-notes/jupyter/theory/2020/05/24/Neural-networks.html" rel="alternate" type="text/html" title="Нейронные сети" /><published>2020-05-24T00:00:00-05:00</published><updated>2020-05-24T00:00:00-05:00</updated><id>https://maxbalashov.github.io/ml-notes/jupyter/theory/2020/05/24/Neural-networks</id><content type="html" xml:base="https://maxbalashov.github.io/ml-notes/jupyter/theory/2020/05/24/Neural-networks.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-24-Neural-networks.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;TL;-DL&quot;&gt;TL; DL&lt;a class=&quot;anchor-link&quot; href=&quot;#TL;-DL&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Выбор функции ошибки:&lt;ol&gt;
&lt;li&gt;Кратко;&lt;/li&gt;
&lt;li&gt;Интуитивный подход;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Устройство нейронных сетей;&lt;/li&gt;
&lt;li&gt;Поиск минимума функции ошибки (TODO: ссылка на градиентный спуск);&lt;/li&gt;
&lt;li&gt;Градиентный спуск в нейросетях (Backpropagation):&lt;ol&gt;
&lt;li&gt;градиентный спуск;&lt;/li&gt;
&lt;li&gt;вычислительные графы.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;&amp;#1055;&amp;#1086;&amp;#1089;&amp;#1090;&amp;#1072;&amp;#1085;&amp;#1086;&amp;#1074;&amp;#1082;&amp;#1072;-&amp;#1079;&amp;#1072;&amp;#1076;&amp;#1072;&amp;#1095;&amp;#1080;&quot;&gt;&amp;#1055;&amp;#1086;&amp;#1089;&amp;#1090;&amp;#1072;&amp;#1085;&amp;#1086;&amp;#1074;&amp;#1082;&amp;#1072; &amp;#1079;&amp;#1072;&amp;#1076;&amp;#1072;&amp;#1095;&amp;#1080;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#1055;&amp;#1086;&amp;#1089;&amp;#1090;&amp;#1072;&amp;#1085;&amp;#1086;&amp;#1074;&amp;#1082;&amp;#1072;-&amp;#1079;&amp;#1072;&amp;#1076;&amp;#1072;&amp;#1095;&amp;#1080;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Главной отличительной особенностью &quot;Обучение с учиталем&quot;(Superwised learning) является наличие обучающей выборки, состоящий из пар $x_i, y_i$, где $x_i$ - признаковое представление объекта, $y_i$ - целевая переменная.
В этой области машинного обучения встают задачи классификации, регрессии и тд.&lt;/p&gt;
&lt;p&gt;Рассмотрим задачу регресии. &lt;code&gt;TODO: рассписать&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;&amp;#1042;&amp;#1099;&amp;#1073;&amp;#1086;&amp;#1088;-&amp;#1092;&amp;#1091;&amp;#1085;&amp;#1082;&amp;#1094;&amp;#1080;&amp;#1080;-&amp;#1086;&amp;#1096;&amp;#1080;&amp;#1073;&amp;#1082;&amp;#1080;&quot;&gt;&amp;#1042;&amp;#1099;&amp;#1073;&amp;#1086;&amp;#1088; &amp;#1092;&amp;#1091;&amp;#1085;&amp;#1082;&amp;#1094;&amp;#1080;&amp;#1080; &amp;#1086;&amp;#1096;&amp;#1080;&amp;#1073;&amp;#1082;&amp;#1080;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#1042;&amp;#1099;&amp;#1073;&amp;#1086;&amp;#1088;-&amp;#1092;&amp;#1091;&amp;#1085;&amp;#1082;&amp;#1094;&amp;#1080;&amp;#1080;-&amp;#1086;&amp;#1096;&amp;#1080;&amp;#1073;&amp;#1082;&amp;#1080;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;&amp;#1048;&amp;#1085;&amp;#1090;&amp;#1091;&amp;#1080;&amp;#1090;&amp;#1080;&amp;#1074;&amp;#1085;&amp;#1099;&amp;#1081;-&amp;#1087;&amp;#1086;&amp;#1076;&amp;#1093;&amp;#1086;&amp;#1076;&quot;&gt;&amp;#1048;&amp;#1085;&amp;#1090;&amp;#1091;&amp;#1080;&amp;#1090;&amp;#1080;&amp;#1074;&amp;#1085;&amp;#1099;&amp;#1081; &amp;#1087;&amp;#1086;&amp;#1076;&amp;#1093;&amp;#1086;&amp;#1076;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#1048;&amp;#1085;&amp;#1090;&amp;#1091;&amp;#1080;&amp;#1090;&amp;#1080;&amp;#1074;&amp;#1085;&amp;#1099;&amp;#1081;-&amp;#1087;&amp;#1086;&amp;#1076;&amp;#1093;&amp;#1086;&amp;#1076;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Задача регрессии, если упростить, сводится к тому, чтобы модель, описывающая &quot;скрытую в данных&quot; функциональную зависимость, не ошибалась. (Не учитываем погрешность при измерениях и переобучение)
Модель не ошибается, когда спрогнозированные значения совпадают с реальными (или стремятся к ним).&lt;/p&gt;
&lt;p&gt;Как можно проверить, насколько модель ошибается?
Нужно придумать подходящую &lt;a href=&quot;TODO&quot;&gt;функцию ошибки&lt;/a&gt;.
Например, мы можем измерять разницу между реальным ($y_i$) и прогнозным ($\hat{y_i}$) значением для объекта из обучающей (или валидационной) выборки:&lt;/p&gt;
&lt;p&gt;
$$y_i - \hat{y_i}$$
&lt;/p&gt;
&lt;p&gt;Но измерение ошибки модели в одной контрольной точке $i$ малоинформативно, возьмем сумму ошибок по всей обучаюшей выборке ($N$ - число наблюдений в выборке):

$$\sum_i^N{y_i - \hat{y_i}}$$
&lt;/p&gt;
&lt;p&gt;Вот тут мы и встречаем причину, почему просто &lt;strong&gt;разность в качестве функции ошибки не подходит&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Ошибки модели на разных примерах из обучающей выборки могут иметь разные знаки, компенсируя друг друга при сложении.&lt;/p&gt;
&lt;p&gt;Пример, пусть существуют две модели A и B, которые имеют следующие ошибки $e_i = y_i - \hat{y_i}$:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;модель&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_1$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_2$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_3$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_4$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$\sum_i^N{e_i}$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;A&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+3 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;B&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+2&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+3&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Получается, что:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Для модели A суммарная ошибка будет равна 0, в то время как суммарная ошибка модели B будет равна 7.&lt;/p&gt;
&lt;p&gt;Исходя из этой логики модель A лучше, чем B.&lt;/p&gt;
&lt;p&gt;Hо это противоречит здравому смыслу, т.к. в каждой точке модель B лучше, т.е. меньше ошибается, чем модель A. ¯\_(ツ)_/¯&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ключевая проблема в том, что &lt;strong&gt;ошибки с разными знаками компенсируют друг друга&lt;/strong&gt;.
Чтобы исправить этот недостаток, можно сделать такое преобразование над ошибками, которое уберет влияние знака.&lt;/p&gt;
&lt;p&gt;Ниже представленны примеры таких преобразований и формулы суммарной ошибки модели в результате этих преобразований:- $|x|$ (модуль числа):$$\sum_i^N{\lvert e_i \rvert} = \sum_i^N{\lvert y_i - \hat{y_i} \rvert}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x^2$ (квадрат числа):

$$\sum_i^N{e_i^2} = \sum_i^N{(y_i - \hat{y_i})^2}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Рассмотрим уже известный пример с добавлением новых функций ошибки:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;модель&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_1$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_2$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_3$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_4$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$\sum_i^N{e_i}$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$\sum_i^N{\lvert e_i \rvert}$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$\sum_i^N{e_i^2}$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;A&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+3 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;6 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;12 000 000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;B&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+2&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+3&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;7&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;7&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Как можно видеть из таблицы, новые функции ошибки отражают следующий факт, что:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Модель A, которая на каждом наблюдении ошибалась сильнее, также сильнее ошибается в общем по всей выборке.&lt;/p&gt;
&lt;p&gt;Поэтому модель A хуже, чем модель B.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Полезное свойство модуля и возведения в квадрат числа - &lt;strong&gt;функции ошибки теперь ограничены снизу нулем&lt;/strong&gt;, те нуль мы получаем в случае, если модель не ошибается и всегда верно предсказывает значение целевой функции.&lt;/p&gt;
&lt;p&gt;Напоследок, предлагаю перейти от суммарных ошибок, к усредненным по наблюдениям, т.е.:- Средняя абсолютная ошибка или &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;MAE&lt;/a&gt; (Mean absolute error):$$\frac{1}{N} \sum_i^N{\lvert y_i - \hat{y_i} \rvert}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Среднеквадратичная ошибка или &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;MSE&lt;/a&gt; (Mean squared error):

$$\frac{1}{N} \sum_i^N{(y_i - \hat{y_i})^2}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Пример для наглядности:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;модель&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_1$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_2$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_3$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$e_4$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;$\frac{1}{N}\sum_i^N{e_i}$&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;MAE&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;MSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;A&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+3 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;-1 000&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;0&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1 500&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;4 000 000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;B&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+2&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+1&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;+3&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1.75&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1.75&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1.75&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Теперь функция ошибки отображает, как &lt;strong&gt;в среднем ошибается модель&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Также размер значения усредненной функции ошибки не зависит напрямую от количества объектов в выборке. Это &lt;strong&gt;удобно для сравнения полученных ошибок на обучающей, валидационной и тестовой выборках&lt;/strong&gt;. Ведь усреднение нивелирует рост значения функции ошибки из-за увеличения числа объектов, по которым ошибка расчитывается.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;&amp;#1053;&amp;#1077;&amp;#1081;&amp;#1088;&amp;#1086;&amp;#1089;&amp;#1077;&amp;#1090;&amp;#1080;&quot;&gt;&amp;#1053;&amp;#1077;&amp;#1081;&amp;#1088;&amp;#1086;&amp;#1089;&amp;#1077;&amp;#1090;&amp;#1080;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#1053;&amp;#1077;&amp;#1081;&amp;#1088;&amp;#1086;&amp;#1089;&amp;#1077;&amp;#1090;&amp;#1080;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;TODO&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;&amp;#1055;&amp;#1086;&amp;#1080;&amp;#1089;&amp;#1082;-&amp;#1084;&amp;#1080;&amp;#1085;&amp;#1080;&amp;#1084;&amp;#1091;&amp;#1084;&amp;#1072;-&amp;#1092;&amp;#1091;&amp;#1085;&amp;#1082;&amp;#1094;&amp;#1080;&amp;#1080;-&amp;#1086;&amp;#1096;&amp;#1080;&amp;#1073;&amp;#1082;&amp;#1080;&quot;&gt;&amp;#1055;&amp;#1086;&amp;#1080;&amp;#1089;&amp;#1082; &amp;#1084;&amp;#1080;&amp;#1085;&amp;#1080;&amp;#1084;&amp;#1091;&amp;#1084;&amp;#1072; &amp;#1092;&amp;#1091;&amp;#1085;&amp;#1082;&amp;#1094;&amp;#1080;&amp;#1080; &amp;#1086;&amp;#1096;&amp;#1080;&amp;#1073;&amp;#1082;&amp;#1080;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#1055;&amp;#1086;&amp;#1080;&amp;#1089;&amp;#1082;-&amp;#1084;&amp;#1080;&amp;#1085;&amp;#1080;&amp;#1084;&amp;#1091;&amp;#1084;&amp;#1072;-&amp;#1092;&amp;#1091;&amp;#1085;&amp;#1082;&amp;#1094;&amp;#1080;&amp;#1080;-&amp;#1086;&amp;#1096;&amp;#1080;&amp;#1073;&amp;#1082;&amp;#1080;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Для начала, выберем функцию ошибки для нашей модели - пусть это будет MSE:

$$L(\theta) = \frac{1}{N} \sum_i^N{(y_i - \hat{y_i})^2}$$
&lt;/p&gt;
&lt;p&gt;TODO: почему MSE??? - оптимизация через град спуск&lt;/p&gt;
&lt;p&gt;Повторимся, в упрощенном и интуитивном понимании, для решения задачи регрессии:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Ищем такую модель, которая ошибается как можно реже, т.е. ее ошибка стремится к минимуму.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Если выразить математически:$$L(\theta) = \frac{1}{N} \sum_i^N{(y_i - \hat{y_i})^2} \rightarrow \min_{\theta}$$&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>